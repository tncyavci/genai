# ğŸ“„ğŸ’¬ PDF ChatBot - Streamlit Version

**Local LLM Destekli PDF Analiz ve Soru-Cevap Sistemi**

## ğŸ‰ Gradio'dan Streamlit'e GeÃ§iÅŸ

Gradio'daki sÃ¼rekli dependency conflict sorunlarÄ± nedeniyle **Streamlit**'e geÃ§tik!

### âœ… Streamlit AvantajlarÄ±:
- **No dependency conflicts** (en bÃ¼yÃ¼k avantaj!)
- Daha stabil Google Colab desteÄŸi
- Daha iyi dosya upload yÃ¶netimi
- Temiz ve modern UI
- Daha iyi session management
- Responsive tasarÄ±m

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### 1. **Local Kurulum**
```bash
# Gereksinimler
pip install -r requirements_colab.txt

# BaÅŸlat
python start_streamlit.py
# veya
streamlit run chat_bot_streamlit.py
```

### 2. **Google Colab**
```python
# Setup Ã§alÄ±ÅŸtÄ±r
!python colab_setup.py

# App'i baÅŸlat
!streamlit run chat_bot_streamlit.py &
```

## ğŸ“ Proje DosyalarÄ±

### ğŸ†• Streamlit Versiyonu:
- `chat_bot_streamlit.py` - Ana Streamlit uygulamasÄ±
- `start_streamlit.py` - Kolay baÅŸlatma scripti
- `requirements_colab.txt` - Streamlit requirements (gradio kaldÄ±rÄ±ldÄ±)
- `colab_setup.py` - Streamlit iÃ§in gÃ¼ncellenmiÅŸ setup
- `README_STREAMLIT.md` - Bu dosya

### ğŸ“š Core ModÃ¼ller:
- `pdf_processor.py` - PDF metin Ã§Ä±karma
- `text_processor.py` - Metin iÅŸleme ve chunking
- `vector_store.py` - Vector database (ChromaDB)
- `llm_service_local.py` - Local LLM servisi

### ğŸ—‘ï¸ KaldÄ±rÄ±lan (Gradio):
- ~~`chat_bot.py`~~ - Gradio versiyonu (artÄ±k kullanmÄ±yoruz)
- ~~`gradio_emergency_fix.py`~~ - ArtÄ±k gerekmiyor!

## ğŸ¯ Desteklenen Modeller

### **ğŸ† Llama 3.1 8B** (Ã–nerilen)
- Memory: ~16GB
- TÃ¼rkÃ§e desteÄŸi mÃ¼kemmel
- Finansal analiz iÃ§in optimize
- HF Model: `meta-llama/Meta-Llama-3.1-8B-Instruct`

### **âš¡ Mistral 7B** (HÄ±zlÄ±)
- Memory: ~14GB  
- Daha hÄ±zlÄ± inference
- Avrupa dilleri desteÄŸi gÃ¼Ã§lÃ¼
- HF Model: `mistralai/Mistral-7B-Instruct-v0.3`

### **ğŸ’ª Llama 3.1 70B** (En GÃ¼Ã§lÃ¼)
- Memory: ~40GB
- En iyi reasoning yeteneÄŸi
- Sadece yÃ¼ksek GPU memory'de Ã§alÄ±ÅŸÄ±r
- HF Model: `meta-llama/Meta-Llama-3.1-70B-Instruct`

## ğŸ’» KullanÄ±m

### 1. **Model SeÃ§imi**
- Sol sidebar'dan model seÃ§in
- "ğŸš€ ChatBot'u BaÅŸlat" butonuna tÄ±klayÄ±n
- Model yÃ¼klenene kadar bekleyin (2-5 dakika)

### 2. **PDF YÃ¼kleme**
- SaÄŸ panelden PDF dosyasÄ±nÄ± seÃ§in
- "ğŸ“¤ YÃ¼kle ve Ä°ÅŸle" butonuna tÄ±klayÄ±n
- Ä°ÅŸlem tamamlanana kadar bekleyin

### 3. **Soru Sorma**
- Ana chat alanÄ±ndan sorunuzu yazÄ±n
- "ğŸ“¤ GÃ¶nder" butonuna tÄ±klayÄ±n
- AI cevabÄ±nÄ± bekleyin

## ğŸ”§ Teknik Detaylar

### **Mimari:**
```
Frontend (Streamlit) 
    â†“
Main App (chat_bot_streamlit.py)
    â†“
LLM Service (llm_service_local.py)
    â†“
Vector Store (ChromaDB) + PDF Processing
```

### **Memory Gereksinimleri:**
- **Minimum:** 8GB RAM, 4GB GPU
- **Ã–nerilen:** 16GB RAM, 16GB GPU
- **Optimal:** 32GB RAM, 24GB+ GPU

### **Desteklenen Formatlar:**
- PDF dosyalarÄ± (metin iÃ§erikli)
- TÃ¼rkÃ§e ve Ä°ngilizce iÃ§erik

## ğŸ› Troubleshooting

### **Streamlit BaÅŸlamÄ±yor:**
```python
# Port kontrolÃ¼
!lsof -i :8501

# Streamlit restart
!pkill -f streamlit
!streamlit run chat_bot_streamlit.py &
```

### **Model YÃ¼klenmiyor:**
```python
# GPU kontrol
import torch
print(torch.cuda.is_available())

# Memory temizle
torch.cuda.empty_cache()
```

### **HuggingFace HatasÄ±:**
```python
# Token gir
from huggingface_hub import login
login(token="your_token_here")
```

## ğŸ”„ Gradio'dan Migration

EÄŸer eski gradio versiyonunu kullanÄ±yordunuz:

1. **Streamlit'e geÃ§:**
   ```bash
   pip uninstall gradio gradio-client
   pip install streamlit>=1.28.0
   ```

2. **Yeni app'i baÅŸlat:**
   ```bash
   streamlit run chat_bot_streamlit.py
   ```

3. **AvantajlarÄ±:**
   - âœ… No more `handle_file` errors!
   - âœ… No more version conflicts!
   - âœ… Better UX and performance
   - âœ… More stable in Colab

## ğŸ“Š Performance

### **Benchmark (Google Colab Pro Plus):**

| Model | Loading Time | Query Response | Memory Usage |
|-------|-------------|----------------|--------------|
| Llama 3.1 8B | 3-5 min | 2-5 sec | ~16GB |
| Mistral 7B | 2-4 min | 1-3 sec | ~14GB |
| Llama 3.1 70B | 8-12 min | 5-10 sec | ~40GB |

## ğŸ¤ KatkÄ±da Bulunma

1. Fork edin
2. Feature branch oluÅŸturun
3. Streamlit best practices'i takip edin
4. Pull request gÃ¶nderin

## ğŸ“„ Lisans

MIT License

## ğŸ†˜ Destek

Sorunlar iÃ§in GitHub Issues kullanÄ±n:
- Streamlit specific sorunlar
- Model yÃ¼kleme problemleri  
- PDF processing hatalarÄ±
- UI/UX geliÅŸtirme Ã¶nerileri

---

**ğŸ‰ Streamlit ile artÄ±k stable ve hÄ±zlÄ± PDF chatbot deneyimi!** 